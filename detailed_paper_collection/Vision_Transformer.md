# **Vision Transformer - Full Paper Collection**

## Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement
- **Tags:** Self-Supervised Learning, Vision Transformer (ViT), Fine-Grained Classification, Contrastive Learning, Knowledge Transfer
## Weakly Supervised Semantic Segmentation via Progressive Confidence Region Expansion
- **Tags:** Semantic Segmentation, Weakly Supervised Learning, Vision Transformer (ViT), Class Activation Maps (CAM), Class-Prototype Enhancement, Confidence Region Mask Expansion
## Less Attention is More: Prompt Transformer for Generalized Category Discovery
- **Tags:** Vision Transformer (ViT), Generalized Category Discovery (GCD), Meta Visual Prompt (MVP), Prompt Transformer (PT), Fine-Grained Classification
## Advancing Semantic Future Prediction through Multimodal Visual Sequence Transformers
- **Tags:** Semantic Segmentation, Multimodal Learning, Vision Transformer (ViT), Multimodal Masked Visual Modeling, VAE-free Tokenization, Hierarchical Tokenization
## Sample- and Parameter-Efficient Auto-Regressive Image Models
- **Tags:** Self-Supervised Learning, Vision Transformer (ViT), Block Causal Mask, Auto-Regressive Modeling, Parameter Efficiency
## PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies
- **Tags:** Anomaly Detection, Vision Transformer (ViT), Adversarial Robustness, Pseudo Anomalies, Foreground-Aware Training
## Spectral State Space Model for Rotation-Invariant Visual Representation Learning
- **Tags:** State Space Models (SSMs), Vision Transformer (ViT), Rotation Invariance, Spectral Decomposition, Graph Laplacian
## Token Cropr: Faster ViTs for Quite a Few Tasks
- **Tags:** Vision Transformer (ViT), Semantic Segmentation, Token Pruning, Auxiliary Prediction Heads, Inference Throughput
## Split Adaptation for Pre-trained Vision Transformers
- **Tags:** Vision Transformer (ViT), Data Augmentation, Privacy Protection, Few-Shot Learning, Quantization
## Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks
- **Tags:** Vision Transformer (ViT), Mixture of Experts (MoE), Sparse Activation Patterns, Post-Training Extraction, Efficiency Optimization
## Star with Bilinear Mapping
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Bilinear Mapping, Low-Rank Decomposition, Linear Complexity
## Hypergraph Vision Transformers: Images are More than Nodes, More than Edges
- **Tags:** Vision Transformer (ViT), Graph Neural Networks (GNNs), Hypergraph Learning, Semantic Relationship Modeling, Dynamic Graph Construction
## Hybrid Reciprocal Transformer with Triplet Feature Alignment for Scene Graph Generation
- **Tags:** Scene Graph Generation, Vision Transformer (ViT), Triplet Alignment, Bidirectional Refinement, Multi-Role Object Handling
## Improving Adversarial Transferability on Vision Transformers via Forward Propagation Refinement
- **Tags:** Vision Transformer (ViT), Adversarial Transferability, Attention Map Diversification, Momentum Token Embedding, Forward Propagation Refinement
## Activating Sparse Part Concepts for 3D Class Incremental Learning
- **Tags:** 3D Object Detection, Long-Tail Learning, Vision Transformer (ViT), Part-Aware Features, Sparse Activation, Task-Wise Classification Fusion
## Learning Person-Specific Animatable Face Models from In-the-Wild Images via a Shared Base Model
- **Tags:** 3D Reconstruction, Avatars, Vision Transformer (ViT), Self-Supervised Learning, Teacher-Student Framework
## FFR:Frequecny Feature Rectification for Weakly Supervised Semantic Segmentation
- **Tags:** Weakly Supervised Semantic Segmentation, Vision Transformer (ViT), Frequency Feature Rectification, Over-smoothing Issue, High-frequency Features
## Parallel Sequence Modeling via Generalization Spatial Propagation Network
- **Tags:** Attention Mechanism, Vision Transformer (ViT), 2D Spatial Structures, Line-Scan Approach, Stability-Context Condition
## Designing Scale-Wise Transformers for Text-to-Image Synthesis
- **Tags:** Text-to-Image Generation, Vision Transformer (ViT), Non-Autoregressive Models, Classifier-Free Guidance, Sampling Efficiency
## MambaOut: Do We Really Need Mamba for Vision?
- **Tags:** Mamba, Vision Transformer (ViT), State Space Model (SSM), Long-Sequence Tasks, Autoregressive Tasks
- **Link:** [Link](https://github.com/yuweihao/MambaOut)

## Your Scale Factors are My Weapon: Targeted Bit-Flip Attacks on Vision Transformers via Scale Factor Manipulation
- **Tags:** Vision Transformer (ViT), Data Augmentation, Quantization, RowHammer Attack, Scale Factor Manipulation
## Self-Supervised Cross-View Correspondence with Predictive Cycle Consistency
- **Tags:** Self-Supervised Learning, Vision Transformer (ViT), Cross-View Correspondence, Cycle-Consistency, Iterative Pseudolabeling
## MambaVision: A Hybrid Mamba-Transformer Vision Backbone
- **Tags:** Mamba, Vision Transformer (ViT), Backbone, Hybrid Architecture, Self-Attention, Hierarchical Design
- **Link:** [Link](https://github.com/NVlabs/MambaVision)

## DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers
- **Tags:** Vision Transformer (ViT), Parameter-Efficient Fine-Tuning (PEFT), Metric Learning, Semantic-Guided Learning, Fine-Tuning Efficiency
## LaVin-DiT: Large Vision Diffusion Transformer
- **Tags:** Diffusion Models, Vision Transformer (ViT), Generative Adversarial Networks (GANs), Spatial-Temporal Variational Autoencoder, In-Context Learning, Unified Multi-Task Training
## Fast Convergence of Diffusion Transformers in a Better High-Dimensional Latent Space
- **Tags:** Diffusion Models, Vision Transformer (ViT), Latent Diffusion Models, High-Dimensional Latent Space, VA-VAE
## Accelerating Multimodel Large Language Models by Searching Optimal Vision Token Reduction
- **Tags:** Multimodal Large Language Models (MLLMs), Vision Transformer (ViT), Token Reduction, Bayesian Optimization, Attention Mechanism
## Your ViT is Secretly an Image Segmentation Model
- **Tags:** Vision Transformer (ViT), Semantic Segmentation, Encoder-only Architecture, Model Scaling, Inference Efficiency
## Breaking the Low-Rank Dilemma of Linear Attention
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Linear Attention, Rank-Augmented Linear Attention (RALA), Rank-Augmented Vision Linear Transformer (RAVLT)
## Flash3D: Super-scaling Point Transformers through Joint Hardware-Geometry Locality
- **Tags:** 3D Point Cloud, Vision Transformer (ViT), Perfect Spatial Hashing (PSH), GPU Tiling, Attention Mechanisms
## Efficient Visual State Space Model for Image Deblurring
- **Tags:** Image Deblurring, Vision Transformer (ViT), State Space Models (SSMs), Frequency Domain Analysis, Geometric Transformations
## DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations
- **Tags:** Vision Transformer (ViT), Multi-Task Learning, Diffeomorphic Transformations, Singular Value Decomposition, Parameter-Efficient Learning
## Correlative and Discriminative Label Grouping for Multi-Label VPT
- **Tags:** Vision Transformer (ViT), Multi-Label Image Classification, Visual Prompt Tuning, Mixture of Experts (MoE), Label Correlation Modeling
## A Polarization-aided Transformer for Image Deblurring via Motion Vector Decomposition
- **Tags:** Deblur, Vision Transformer (ViT), Motion Decomposition, Radial Stripe Attention, Polar-System Convolution
## APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian Based Reconstruction for Vision Transformers
- **Tags:** Vision Transformer (ViT), Model Pruning, Post-Training Quantization, Hessian Loss, Activation Function Optimization
## Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking
- **Tags:** Vision Transformer (ViT), Visual Tracking, Occlusion-Robust Representations, Knowledge Distillation, Real-Time Tracking
- **Link:** [Link](https://github.com/qtyz-ogvm/ORTrack)

## DeepCompress-ViT: Rethinking Model Compression to Enhance Efficiency of Vision Transformers at the Edge
- **Tags:** Vision Transformer (ViT), Model Pruning, Unified Compression Training (UCT), Edge Computing, Matrix Multiplication Optimization
## Revisiting Audio-Visual Segmentation with Vision-Centric Transformer
- **Tags:** Audio-Visual Segmentation, Vision Transformer (ViT), Prototype Prompted Query Generation, Audio-Visual Information Aggregation, Vision-Derived Queries
## PLeaS - Merging Models with Permutations and Least Squares
- **Tags:** Model Merging, Vision Transformer (ViT), Permutation Symmetry, Least Squares Optimization, Cross-Model Merging
## CARE Transformer: Mobile-Friendly Linear Visual Transformer via Decoupled Dual Interaction
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Linear Attention, Mobile-Friendly, Dual Interaction
## Prompt-CAM: Prompt-Class Attention Map for Fine-grained Interpretation
- **Tags:** Vision Transformer (ViT), Fine-grained Interpretation, Class-specific Prompts, Multi-head Attention Maps, Visual Prompt Tuning (VPT)
## Similarity-Guided Layer-Adaptive Vision Transformer for UAV Tracking
- **Tags:** Vision Transformer (ViT), Visual Tracking, Layer Adaptation, Real-Time Tracking, UAV Applications
## Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Feature Attribution, Information Bottleneck Principle, Variational Approach
## EfficientViM: Efficient Vision Mamba with Hidden State Mixer based State Space Duality
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, State Space Model, Channel Mixing, Multi-Stage Fusion
## SATA: Spatial Autocorrelation Token Analysis for Enhancing the Robustness of Vision Transformers
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Spatial Autocorrelation, Token Analysis, Feed-Forward Network Optimization
## Spiking Transformer with Spatial-Temporal Attention
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Spike-based Processing, Temporal Dependencies, Energy-Efficient Computing
## Mamba-Adaptor: State Space Model Adaptor for Visual Recognition
- **Tags:** Mamba, Vision Transformer (ViT), Self-Supervised Learning, Memory Augmentation, Dilated Convolutional Kernels, Transfer Learning
## Non-Natural Image Understanding with Advancing Frequency-based Vision Encoders
- **Tags:** Multimodal Large Language Models (MLLMs), Vision Transformer (ViT), Frequency Modulation, Non-Natural Image Understanding, Fourier Decomposition
## FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation
- **Tags:** Vision Transformer (ViT), Model Pruning, Quantization Loss, Fisher Information Matrix, Low-Bit Quantization
## Layer- and Timestep-Adaptive Differentiable Token Compression Ratios for Efficient Diffusion Transformers
- **Tags:** Diffusion Models, Vision Transformer (ViT), Dynamic Computation Routing, Mixture-of-Depths, Differentiable Compression Ratios
## SPMTrack: Spatio-Temporal Parameter-Efficient Fine-Tuning with Mixture of Experts for Scalable Visual Tracking
- **Tags:** Visual Tracking, Mixture of Experts, Vision Transformer (ViT), Spatio-Temporal Modeling, Parameter-Efficient Fine-Tuning, Scalable Tracking
## Lessons Learned from a Unifying Empirical Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition
- **Tags:** Vision Transformer (ViT), Parameter-Efficient Fine-Tuning (PEFT), Ensemble Methods, Distribution Shift Robustness, Hyper-parameter Tuning
## LSNet: See Large, Focus Small
- **Tags:** Lightweight Networks, Vision Transformers, LS Convolution, Dynamic Heteroscale Vision, Lightweight Model Design
## Adventurer: Optimizing Vision Mamba Architecture Designs for Efficiency
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Linear Complexity, Patch Tokens, Causal Inference Framework
## BHViT: Binarized Hybrid Vision Transformer
- **Tags:** Vision Transformer (ViT), Model Pruning, Binarization, Shift Operations, Quantization Decomposition
## Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment
- **Tags:** Vision Transformer (ViT), Image Quality Assessment, Tokenization, Multiscale Information, Aspect Ratio Preservation
- **Link:** [Link](https://github.com/FBehrad/Charm)

## BlockDance: Reuse Structurally Similar Spatio-Temporal Features to Accelerate Diffusion Transformers
- **Tags:** Diffusion Models, Vision Transformer (ViT), Feature Reuse, Instance-Specific Acceleration, Spatio-Temporal Features
## IceDiff: High Resolution and High-Quality Arctic Sea Ice Forecasting with Generative Diffusion Prior
- **Tags:** Diffusion Models, Vision Transformer (ViT), High-Resolution Forecasting, Zero-Shot Guided Sampling, Patch-Based Method
## Let Humanoid Robots Go Hiking! Integrative Skill Development over Complex Trails
- **Tags:** Embodied AI, Hierarchical Reinforcement Learning (HRL), Temporal Vision Transformer, Privileged Learning, Variational Autoencoder (VAE)
## FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute
- **Tags:** Diffusion Models, Vision Transformer (ViT), Dynamic Compute Allocation, Efficient Inference, Video Generation
## Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better
- **Tags:** Video Understanding, Temporal Attention, Point Tracking, Temporal Alignment, Vision Transformers
## LibraGrad: Balancing Gradient Flow for Universally Better Vision Transformer Attributions
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Gradient Flow Balancing, Attribution Faithfulness, Post-hoc Explanation Methods
- **Link:** [Link](https://nightmachinery.github.io/LibraGrad/)

## L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers
- **Tags:** Neural Architecture Search (NAS), Vision Transformer (ViT), Zero-Shot Learning, Training-free NAS, Proxy Combination
## Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks
- **Tags:** Diffusion Models, Vision Transformer (ViT), Speech Audio Conditioning, Identity Reference Network, Long-Duration Video Extrapolation
## Building Vision Models upon Heat Conduction
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Heat Conduction Operator (HCO), Discrete Cosine Transformation (DCT), Global Receptive Fields
## OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels
- **Tags:** Backbone, Vision Transformer (ViT), Dynamic Convolution, Top-Down Attention, Biomimetic Design
## Rethinking Token Reduction with Parameter-Efficient Fine-Tuning in ViT for Pixel-Level Tasks
- **Tags:** Vision Transformer (ViT), Parameter-Efficient Fine-Tuning (PEFT), Token Reduction, Pixel-Level Tasks, Attention Diversity, Computational Efficiency, Transformer Optimization
## Mamba-Reg: Vision Mamba Also Needs Registers
- **Tags:** Vision Transformer (ViT), Self-Supervised Learning, Register Tokens, Uni-directional Inference, Semantic Segmentation
## Closest Neighbors are Harmful for Lightweight Masked Auto-encoders
- **Tags:** Self-Supervised Learning, Vision Transformer (ViT), Lightweight Models, Semantic Aliasing, NoR-MAE
## Attend to Not Attended: Structure-then-Detail Token Merging for Post-training DiT Acceleration
- **Tags:** Diffusion Models, Vision Transformer (ViT), Token Merging, Post-training Acceleration, Dynamic Compression
## BOE-ViT: Boosting Orientation Estimation with Equivariance in Self-Supervised 3D Subtomogram Alignment
- **Tags:** Vision Transformer (ViT), 3D Reconstruction, Self-Supervised Learning, Equivariance, Cryo-ET, Polyshift Module, Multi-Axis Rotation Encoding (MARE), Cryo-ET Data Analysis
