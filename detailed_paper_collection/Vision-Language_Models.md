# **Vision-Language Models - Full Paper Collection**

## Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering
- **Tags:** Vision-Language Models (VLMs), Medical Image Analysis, Contrastive Learning, Knowledge Fusion, Optimal Transport Theory, Gated Cross-Attention, Hard Negative Mining
## Chain of Attack: On the Robustness of Vision-Language Models Against Transfer-Based Adversarial Attacks
- **Tags:** Vision-Language Models (VLMs), Adversarial Attacks, Multi-Modal Semantics, Black-Box Attacks, Adversarial Transferability
## A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Few-Shot Learning, Kernel Methods, Reproducing Kernel Hilbert Space (RKHS), Proximal Regularization
## TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Adversarial Robustness, Test-Time Defense, Bimodal Prompt Tuning, Multi-View Entropy Optimization
## MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation
- **Tags:** Embodied AI, Vision-Language Models (VLMs), Policy Adaptation, Bi-level Optimization, Trajectory Generation
## DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Parameter-Efficient Adaptation, Image-Video Features Fusion, Alignment Distillation
## SpiritSight Agent: Advanced GUI Agent with One Look
- **Tags:** Vision-Language Models (VLMs), Graphical User Interface (GUI), Universal Block Parsing (UBP), GUI-Lasagne Dataset, Element Grounding
## CLIP-driven Coarse-to-fine Semantic Guidance for Fine-grained Open-set Semi-supervised Learning
- **Tags:** Vision-Language Models (VLMs), Fine-grained Open-set Semi-supervised Learning, Cross-modality Guidance, Visual-Semantic Injection, Dual-Guidance Framework
## RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics
- **Tags:** Vision-Language Models (VLMs), 3D Point Cloud, Spatial Understanding, Robotics, Spatial Affordance Prediction, Spatial Relationship Prediction, Robotics Manipulation
## Task-Aware Clustering for Prompting Vision-Language Models
- **Tags:** Vision-Language Models, Prompt Learning, Task-Aware Clustering, Masked Attention Mechanism, Pre-context Interaction
## Argus: A Compact and Versatile Foundation Model for Vision
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Multitask Learning, Lightweight Adapters, Task-Specific Decoders
## DViN: Dynamic Visual Routing Network for Weakly Supervised Referring Expression Comprehension
- **Tags:** Vision-Language Models (VLMs), Weakly Supervised Learning, Sparse Routing Mechanism, Routing-based Feature Alignment, Weakly Supervised REC
- **Link:** [Link](https://anonymous.4open.science/r/DViN-7736)

## Realistic Test-Time Adaptation of Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Test-Time Adaptation (TTA), Zero-Shot Learning, Regularization Techniques, Online Adaptation, Statistical Anchoring
## Can Large Vision-Language Models Correct Grounding Errors By Themselves?
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Self-Correction Framework, Semantic Grounding, Iterative Improvement
## MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders
- **Tags:** Knowledge Distillation, Vision-Language Models (VLMs), Low-Rank Adaptation (LoRA), Mixture-of-Experts (MoEs), Attention-Based Distillation
## SpatialCLIP: Learning 3D-aware Image Representations from Spatially Discriminative Language
- **Tags:** CLIP, Vision-Language Models (VLMs), 3D-aware Image Representations, Spatial Reasoning, 3D-inspired ViT, Hard Negative Captions, SpatialBench
## PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Token Reduction, Clustering Algorithm, FlashAttention Compatibility
## CALICO: Multi-Image Pixel-Grounded Object Comparison by Parts with Large Language Models
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Part-Level Segmentation, Multi-Image Understanding, Parameter-Efficient Learning
## GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks
- **Tags:** Vision-Language Models (VLMs), Generative Flow Networks (GFlowNets), Non-Markovian Decision Process, Chain-of-Thought Reasoning, Task-Based Rewards
## MASH-VLM: Mitigating Action-Scene Hallucination in Video-LLMs through Disentangled Spatial-Temporal Representations
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Disentangled Representations, Attention Mechanisms, Positional Encoding
## Mamba as a Bridge: Where VFM Meets VLM for Domain-Generalized Semantic Segmentation
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Mamba-based fusion, Domain Generalization, Hybrid Attention-Mamba
## Believing is Seeing: Unobserved Object Detection using Generative Models
- **Tags:** Object Detection, Diffusion Models, Vision-Language Models (VLMs), Unobserved Object Detection, 2.5D Object Detection, 3D Object Detection
## Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation
- **Tags:** Semantic Segmentation, Vision-Language Models (VLMs), Cost Aggregation, Compositional Loss, DINO Features
## FireEdit: Fine-grained Instruction-based Image Editing via Region-aware Vision Language Model
- **Tags:** Vision-Language Models (VLMs), Image Editing, Diffusion Models, Region-aware VLM, Time-Aware Target Injection, Hybrid Visual Cross Attention
## VELOCITI: Benchmarking Video-Language Compositional Reasoning with Strict Entailment
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Strict Entailment, Compositional Reasoning, Video-Language Entailment
## Narrating the Video: Boosting Text-Video Retrieval via Comprehensive Utilization of Frame-Level Captions
- **Tags:** Vision-Language Models (VLMs), Text-Video Retrieval, Cross-Modal Interaction, Query-Aware Filtering, Dual-Modal Matching
## Synthetic Visual Genome
- **Tags:** Vision-Language Models (VLMs), Scene Graph Generation, Self-Distillation, Instruction Tuning, GPT4-V Integration
## Synthetic Data is an Elegant GIFT for Continual Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Continual Learning, Diffusion Models, Synthetic Data, Contrastive Distillation, Adaptive Weight Consolidation, Image-Text Alignment
## Unveiling Visual Perception in Language Models: A Attention Head Analysis Approach
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Attention Mechanism, Visual Token Processing, Multimodal Adaptation
## Paint by Inpaint: Learning to Add Image Objects by Removing Them First
- **Tags:** Image Editing, Diffusion Models, Vision-Language Models, Large Language Models, Object Addition, Textual Instructions, Dataset Curation
## Uncertain Multimodal Intention and Emotion Understanding in the Wild
- **Tags:** Multimodal Learning, Vision-Language Models (VLMs), Uncertainty Handling, Emotion-Intention Correlation, Modality Asynchronous Learning
## Advancing Fine-Grained Compositional Alignment in Video-Text Models
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Temporal Alignment, Hierarchical Loss, Pretraining Strategy
## O-TPT: Orthogonality Constraints for Calibrating Test-time Prompt Tuning in Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Test-time Prompt Tuning, Calibration, Orthogonality Constraints, Textual Feature Dispersion, Fine-Grained Classification
## Whatâ€™s in the Image? A Deep-Dive into the Vision of Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Attention Mechanisms, Cross-Modal Learning, Spatial Localization
## SAIST: Segment Any Infrared Small Target Model Guided by Contrastive Language-Image Pretraining
- **Tags:** Infrared Small Target Detection, Vision-Language Models (VLMs), Multimodal Learning, Contrastive Language-Image Pretraining (CLIP), Infrared Imaging
## Evaluating Vision-Language Models as Evaluators in Path Planning
- **Tags:** Vision-Language Models (VLMs), Path Planning, Plan Evaluation, Low-Level Perception, Discriminative Adaptation
## Mosaic3D: Foundation Dataset and Model for Open-Vocabulary 3D Segmentation
- **Tags:** 3D Semantic Segmentation, Vision-Language Models (VLMs), Open-Vocabulary Learning, Contrastive Learning, 3D Scene Understanding
## Post-pre-training for Modality Alignment in Vision-Language Foundation Models
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Modality Alignment, Feature Space Optimization, Zero-Shot Learning Enhancement
## Vision-Language Embodiment for Monocular Depth Estimation
- **Tags:** Depth Estimation, Embodied AI, Vision-Language Models (VLMs), Monocular Depth Estimation, Camera Model Integration, Text-Image Fusion
## CTRL-O: Language-Controllable Object-Centric Visual Representation Learning
- **Tags:** Object Detection, Vision-Language Models (VLMs), Language-Controllable Learning, Object-Language Binding, Instance-Specific Representation
## ReVisionLLM: Recursive Vision-Language Model for Temporal Grounding in Hour-Long Videos
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Temporal Grounding, Recursive Model, Hierarchical Training
## Compositional Caching for Training-free Open-vocabulary Attribute Detection
- **Tags:** Vision-Language Models (VLMs), Open-vocabulary Attribute Detection, Large Language Models (LLMs), Training-free Method, Attribute-Object Compatibility, Soft Attribute Labeling
## ResCLIP: Residual Attention for Training-free Dense Vision-language Inference
- **Tags:** CLIP, Vision-Language Models (VLMs), Self-Supervised Learning, Residual Attention, Semantic Feedback Refinement, Dense Vision-Language Inference
## LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Label Propagation, Open-Vocabulary Segmentation, Pixel-Level Refinement, Cross-Modal Alignment
## CoSpace: Benchmarking Continuous Space Perception Ability for Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Continuous Space Perception, Multi-Image Understanding, Spatial Reasoning, Benchmarking
## SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving
- **Tags:** Vision-Language Models (VLMs), Autonomous Driving, Trajectory Chain-of-Thought (T-CoT), Temporal Decoupling, Feature-Level Knowledge Sharing
## VISCO: Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Fine-Grained Critique, Chain-of-Thought Analysis, LookBack Strategy
## HOIGPT: Learning Long Sequence Hand-Object Interaction with Language Models
- **Tags:** 3D Generation, Vision-Language Models (VLMs), Hand-Object Interaction, Tokenization, Motion-Aware Language Model
## PHGC: Procedural Heterogeneous Graph Completion for Natural Language Task Verification in Egocentric Videos
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Heterogeneous Graph, Cross-Modal Alignment, Egocentric Video Analysis
- **Link:** [Link](https://anonymous.4open.science/r/PHGC-7A1B)

## FineLIP: Extending CLIPâ€™s Reach via Fine-Grained Alignment with Longer Text Inputs
- **Tags:** CLIP, Vision-Language Models (VLMs), Zero-Shot Learning, Fine-Grained Alignment, Dynamic Token Aggregation, Longer Text Inputs
## Do computer vision foundation models learn the low-level characteristics of the human visual system?
- **Tags:** Self-Supervised Learning, Vision-Language Models (VLMs), Contrast Detection, Contrast Masking, Human Visual System (HVS)
## FINECAPTION: Compositional Image Captioning Focusing on Wherever You Want at Any Granularity
- **Tags:** Vision-Language Models (VLMs), Image Captioning, Compositional Image Captioning, Fine-Grained Visual Understanding, Region-Based Captioning
## FastVLM: Efficient Vision Encoding for Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, FastViTHD, Time-to-First-Token (TTFT), Hybrid Vision Encoder
## Vision-Language Model IP Protection via Prompt-based Learning
- **Tags:** Vision-Language Models (VLMs), CLIP, Intellectual Property (IP) Protection, Prompt-based Learning, Feature Transfer Prevention, Style-Enhancement Branch, Performance Metrics for IP Protection
## NLPrompt: Noise-Label Prompt Learning for Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Noisy-Label Learning, Prompt Learning, Optimal Transport, Noisy-Label Robustness
## Reasoning to Attend: Try to Understand How [SEG] Token Works
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Semantic Correspondence, Attention Mechanism, Pseudo Images
## SeeGround: See and Ground for Zero-shot Open-Vocabulary 3D Visual Grounding
- **Tags:** 3D Visual Grounding, Vision-Language Models (VLMs), Zero-Shot Learning, Perspective Adaptation, Fusion Alignment, Hybrid Scene Representation
## Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Automated Dataset Generation, Cross-Platform Generalization, UI Component Detection
## Vision-Language Gradient Descent-driven All-in-One Deep Unfolding Networks
- **Tags:** Vision-Language Models (VLMs), Image Restoration, Deep Unfolding Networks (DUNs), Proximal Gradient Descent (PGD), Hierarchical Feature Unfolding, Multi-Degradation Restoration
## GOAL: Global-local Object Alignment Learning
- **Tags:** Vision-Language Models (VLMs), CLIP, Local Image-Sentence Matching, Token Similarity-based Learning, Image-Lengthy Text Retrieval
## VLMs-Guided Representation Distillation for Efficient Vision-Based Reinforcement Learning
- **Tags:** Vision-Language Models (VLMs), Reinforcement Learning, Self-Supervised Learning, Semantic Representation, Sample Efficiency, Prompting-Reasoning Pipeline
## DH-Set: Improving Vision-Language Alignment with Diverse and Hybrid Set-Embeddings Learning
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Semantic Importance Dissecting, Hybrid Embedding, Finer-Grained Diversity Constraint
## Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis
- **Tags:** Vision-Language Models (VLMs), Medical Image Analysis, Dynamic Soft Labels, Negation-Aware Learning, CXR-Align Benchmark
## Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Recurrent Neural Networks, Cross-modal Retrieval, Sigmoidal Gates
## Lifelong Knowledge Editing for Vision Language Models with Low-Rank Mixture-of-Experts
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Model Editing, Low-Rank Mixture-of-Experts, Knowledge Editing, Semantic Relevance, Multi-Expert Fusion
## Effective SAM Combination for Open-Vocabulary Semantic Segmentation
- **Tags:** Semantic Segmentation, Vision-Language Models (VLMs), Open-Vocabulary Learning, Efficient Inference, Pseudo Prompts
## Hierarchical Knowledge Prompt Tuning for Multi-task Test-Time Adaptation
- **Tags:** Vision-Language Models (VLMs), Test-Time Adaptation, Prompt Tuning, Knowledge Distillation, Multi-task Learning
## Bridging the Vision-Brain Gap with an Uncertainty-Aware Blur Prior
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Uncertainty Estimation, Brain Signal Processing, Zero-Shot Retrieval
- **Link:** [Link](https://github.com/HaitaoWuTJU/Uncertainty-aware-Blur-Prior)

## DART: Disease-aware Image-Text Alignment and Self-correcting Re-alignment for Trustworthy Radiology Report Generation
- **Tags:** Medical Image Analysis, Vision-Language Models (VLMs), Contrastive Learning, Self-correction Module, Disease Classification
## Stop learning it all to mitigate visual hallucination, Focus on the hallucination target.
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Hallucination Mitigation, Preference Learning, Targeted Learning
## Evaluating generated 3D assets using multiview Large Language Models
- **Tags:** 3D Generation, Vision-Language Models (VLMs), Text-to-3D Evaluation, 3D Surface Normals Analysis, User-Aligned Metrics
## JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems
- **Tags:** Visual Tracking, Vision-Language Models (VLMs), UAV Tracking, Intent Understanding, Thermal Imaging
## DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models
- **Tags:** Vision-Language Models, CLIP, Prompt Tuning, Weighting-Decoupling, Dynamic Hard Negative Optimizer, Feature Channel Invariance
## Hierarchy-Aware Evaluation of Free-Form Predictions From Vision-And-Language Models
- **Tags:** Vision-Language Models (VLMs), Zero-Shot Learning, Taxonomic Evaluation, Hierarchical Precision and Recall, Fine-Grained Visual Classification
## DistinctAD: Distinctive Audio Description Generation in Contexts
- **Tags:** Vision-Language Models (VLMs), Data Augmentation, CLIP-AD adaptation, Contextual Expectation-Maximization Attention, Distinctive word prediction loss
## PromptHMR: Promptable Human Mesh Recovery
- **Tags:** 3D Human Pose Estimation, 3D Human Mesh Estimation, Vision-Language Models (VLMs), Transformer, Spatial Prompts, Semantic Prompts, Temporal Coherence
## Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Visual Attention Grounding, Object-Centric Grounding, Language-Guided Visual Engagement
## Task Preference Optimization: Improving Multimodal Large Language Models Performance with Vision Task Alignment
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Task Preference Optimization, Learnable Task Tokens, Zero-Shot Learning
## Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Datasets and Benchmarks, Open-Weight Models, Dataset Creation, Human Evaluation
## R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning
- **Tags:** Vision-Language Models (VLMs), Adversarial Robustness, Test-Time Prompt Tuning, Entropy Minimization, Reliability-Based Ensembling
## Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body
- **Tags:** Vision-Language Models (VLMs), Image Editing, Abnormality Detection, Human Body Reconstruction, Visual Synthesis
## Your Large Vision-Language Model Only Needs A Few Attention Heads For Visual Grounding
- **Tags:** Vision-Language Models (VLMs), Visual Grounding, Attention Heads, Training-Free Framework, Text-to-Image Attention Maps
## Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Entailment Tree Reasoning, De-biasing Techniques, Commonsense Reasoning
## STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Dynamic Prompting, Temporal Variance, Intra-frame Attention
## DPSeg: Dual-Prompt Cost Volume Learning for Open-Vocabulary Semantic Segmentation
- **Tags:** Semantic Segmentation, Vision-Language Models (VLMs), Open-Vocabulary Learning, Dual-Prompt Framework, Cost Volume Learning, Semantic-Guided Prompt Refinement
## Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception
- **Tags:** Vision-Language Models (VLMs), Hallucination Mitigation, Synthetic Data-Driven Framework, Preference Optimization, Counterfactual Presupposition
## Align-KD: Distilling Cross-Modal Alignment Knowledge for Mobile Vision-Language Model
- **Tags:** Knowledge Distillation, Vision-Language Models (VLMs), Cross-Modal Alignment, Mobile AI, Model Compression
## TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Inference Time Optimization, FlashAttention Compatibility, KV Cache Reduction, Visual Token Pruning
## MambaVLT: Time-Evolving Multimodal State Space Model for Vision-Language Tracking
- **Tags:** Vision-Language Models (VLMs), Visual Tracking, State Space Model (SSM), Temporal Information Modeling, Modality-Selection Module
## HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), High-Resolution Image Processing, SliceRestore Adapter, Self-Mining Sampler, EntityGrid-QA
## Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions
- **Tags:** Embodied AI, 3D Object Detection, Vision-Language Models (VLMs), 3D Affordance Grounding, Multi-Modal Fusion, Cognitive Science
## OpenSDI: Spotting Diffusion-Generated Images in the Open World
- **Tags:** Diffusion Models, Vision-Language Models (VLMs), Image Manipulation Detection, Foundation Model Synergy, Open-World Benchmark
## Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Actor-Critic Paradigm, Direct Preference Optimization (DPO), Rule-based Reward (RBR)
## DynRefer: Delving into Region-level Multimodal Tasks via Dynamic Resolution
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Dynamic Resolution Adaptation, Region-Level Multimodal Tasks, Human Visual Cognition Mimicry
## Reproducible Vision-Language Models Meet Concepts Out of Pre-Training
- **Tags:** Vision-Language Models (VLMs), Zero-Shot Learning, Name-Tuning, Image-Text Alignment, OpenCLIP
## VoCo-LLaMA: Towards Vision Compression with Large Language Models
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Vision Compression, Attention Distillation, Video Understanding, Attention Distillation, Temporal Correlation Understanding, Scalable Multi-modal Applications
## VL2Lite: Task-Specific Knowledge Distillation from Large Vision-Language Models to Lightweight Networks
- **Tags:** Knowledge Distillation, Vision-Language Models (VLMs), Image Classification, Lightweight Networks, Multi-Modal Knowledge Transfer
## Enhanced Visual-Semantic Interaction with Tailored Prompts for Pedestrian Attribute Recognition
- **Tags:** Pedestrian Attribute Recognition, Vision-Language Models (VLMs), Prompt Learning, Bimodal Interaction, Dataset Creation
## Do Visual Imaginations Improve Vision-and-Language Navigation Agents?
- **Tags:** Vision-Language Models (VLMs), Diffusion Models, Text-to-Image Synthesis, Auxiliary Loss, Landmark Cues
- **Link:** [Link](https://www.akhilperincherry.com/VLN-Imagine-website/)

## VASparse: Towards Efficient Visual Hallucination Mitigation via Visual-Aware Token Sparsification
- **Tags:** Vision-Language Models (VLMs), Visual Hallucination Mitigation, Token Sparsification, Attention Recalibration, Contrastive Decoding
- **Link:** [Link](https://anonymous.4open.science/r/VASparse-128C)

## CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Visual Chain-of-Thought Reasoning, Autoregressive Frame Prediction, Sensorimotor Control
## Locality-Aware Zero-Shot Human-Object Interaction Detection
- **Tags:** Zero-Shot Learning, Vision-Language Models (VLMs), Human-Object Interaction Detection, Spatial Priors, Interaction Pattern Recognition
## Separation of powers: On segregating knowledge from observation in LLM-enabled knowledge-based visual question answering
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Knowledge Distillation, Visual Question Answering, Question-Aware Captioning, GPT-4 Augmented Dataset, State-of-the-Art Benchmarks
## Marten: Visual Question Answering with Mask Generation for Multi-modal Document Understanding
- **Tags:** Vision-Language Models (VLMs), Multimodal Large Language Models (MLLMs), Mask Generation, Document-Level Understanding, Spatially-Aware Feature Learning
## Seeing the Abstract: Translating the Abstract Language for Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Text-to-Image Generation, Abstract Language Processing, Fashion Domain Analysis, Training-Free Enhancement
## Document Haystacks:  Vision-Language Reasoning Over Piles of 1000+ Documents
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Retrieval-Augmented Generation, Document Retrieval, Multimodal Encoders
## Seeing more with less: human-like representations in vision models
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Foveated Sampling, Variable Resolution Processing, Human-like Visual Processing
## CustomKD: Customizing Large Vision Foundation for Edge Model Improvement via Knowledge Distillation
- **Tags:** Knowledge Distillation, Vision-Language Models (VLMs), Model Discrepancy Reduction, Unsupervised Domain Adaptation, Semi-Supervised Learning
## VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge
- **Tags:** Vision-Language Models (VLMs), Medical Image Analysis, Domain Expert Models, Instruction Fine-Tuning, Healthcare AI
## Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Infant Learning, Visual Concept Neurons, Egocentric Vision
## Zero-shot 3D Question Answering via Voxel-based Dynamic Token Compression
- **Tags:** 3D Question Answering, Vision-Language Models (VLMs), Dynamic Token Compression, 3D Spatial Priors, Visual Semantics
## POPEN: Preference-Based Optimization and Ensemble for LVLM-Based Reasoning Segmentation
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Preference-Based Optimization, Ensemble Learning, Curriculum Learning
## MotionBench: Benchmarking and Improving Fine-grained Video Motion Understanding for Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Fine-Grained Motion Comprehension, Through-Encoder Fusion, Video Feature Compression
## NVILA: Efficient Frontier Visual Language Models
- **Tags:** Vision-Language Models (VLMs), Efficiency Optimization, Scale-then-Compress Approach, High-Resolution Image Processing, Long Video Processing
## Multi-layer Visual Feature Fusion in Multimodal LLMs: Methods, Analysis, and Best Practices
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Feature Fusion, Layer Selection, Model Performance Optimization
## Multi-modal Knowledge Distillation-based Human Trajectory Forecasting
- **Tags:** Knowledge Distillation, Autonomous Driving, Multimodal Learning, Pedestrian Trajectory Forecasting, Vision-Language Models, Resource-Constrained Systems
## VL-RewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models
- **Tags:** Vision-Language Models (VLMs), Datasets and Benchmarks, Multimodal Learning, Model Evaluation, Visual Perception
## Text Augmented Correlation Transformer For Few-shot Classification & Segmentation
- **Tags:** Few-shot Learning, Semantic Segmentation, Vision-Language Models (VLMs), Textual Cues Integration, Dual-Modal Prediction, Weakly Supervised Learning
## Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning
- **Tags:** Vision-Language Models (VLMs), In-Context Learning, Reinforcement Learning, Multi-modal Learning, Few-Shot Learning, Visual Question-Answering
## COSMOS: Cross-Modality Self-Distillation for Vision Language Pretraining
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Cross-Modality Self-Distillation, Text-Cropping Strategy, Cross-Attention Module
## HyperSeg: Hybrid Segmentation Assistant with Fine-grained Visual Perceiver
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Video Object Segmentation, Hybrid Entity Recognition, Fine-Grained Visual Perceiver, Temporal Adapter
## Single Domain Generalization for Few-Shot Counting via Universal Representation Matching
- **Tags:** Few-Shot Counting, Domain Generalization, Vision-Language Models (VLMs), Universal Representation Matching, Correlation Map Construction, Domain Shift Robustness
## SkySense-O: Towards Open-World Remote Sensing Interpretation with Vision-Centric Visual-Language Modeling
- **Tags:** Vision-Language Models (VLMs), Remote Sensing Image Analysis, Zero-Shot Learning, Image-Text Alignment, Visual Self-Supervised Learning
## Global-Local Tree Search in VLMs for 3D Indoor Scene Generation
- **Tags:** Vision-Language Models (VLMs), 3D Generation, Tree Search Algorithm, Hierarchical Scene Decomposition, Emoji Grid Representation
## MBQ: Modality-Balanced Quantization for Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Post-Training Quantization (PTQ), Quantization Sensitivity, Modality-Specific Calibration, GPU Kernel Optimization
## Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation
- **Tags:** Text-to-Image Generation, Uncertainty Quantification, Large Vision-Language Models (LVLMs), Aleatoric Uncertainty, Epistemic Uncertainty, Semantic Text Space Analysis
## Enhancing Few-Shot Class-Incremental Learning via Training-Free Bi-Level Modality Calibration
- **Tags:** Few-Shot Learning, CLIP, Vision-Language Models (VLMs), Bi-level Modality Calibration, Training-Free Framework, Intra-modal and Inter-modal Calibration
## ShowUI: One Vision-Language-Action Model for GUI Visual Agent
- **Tags:** Vision-Language Models (VLMs), Graph Neural Networks (GNNs), UI-Guided Visual Token Selection, Interleaved Vision-Language-Action Streaming, Small-Scale High-Quality GUI Instruction-Following Datasets
## DINOv2 Meets Text: A Unified Framework for Image- and Pixel-Level Vision-Language Alignment
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Open-Vocabulary Tasks, Zero-Shot Classification, Semantic Segmentation
## LLAVIDAL: A Large LAnguage VIsion Model for Daily Activities of Living
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Human-Object Interaction (HOI), Curriculum Learning, 3D Skeletons
- **Link:** [Link](https://llavidal.github.io/llavidal/)

## Recreating 1940s Tom and Jerry with Test-Time Training
- **Tags:** Video Generation, Vision-Language Models, Test-Time Training, Long-Form Video Generation, Hybrid Attention Mechanism
## VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Anomaly Detection, Explainable AI, Verbalized Learning, Frame-Level Anomaly Detection
## Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion
- **Tags:** Vision-Language Models (VLMs), Multimodal Large Language Models (MLLMs), Depth-Breadth Fusion (DBFusion), Generative Vision Encoder, Vision-Language Alignment
## Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models
- **Tags:** Video Understanding, Vision-Language Models (VLMs), Spatio-Temporal Alignment Block (STAB), Parameter Efficiency, Local Spatio-Temporal Encoding
## BACON: Improving Clarity of Image Captions via Bag-of-Concept Graphs
- **Tags:** Vision-Language Models (VLMs), Image Captioning, Structured Captioning, JSON Dictionary Integration, Open-Vocabulary Object Detection
## Probabilistic Prompt Distribution Learning for Animal Pose Estimation
- **Tags:** Vision-Language Models (VLMs), Long-Tail Learning, Probabilistic Prompting, Cross-Modal Fusion, Animal Pose Estimation
## FLAIR: VLM with Fine-grained Language-informed Image Representations
- **Tags:** Vision-Language Models (VLMs), Fine-Grained Retrieval, Text-Conditioned Attention Pooling, Zero-Shot Semantic Segmentation, Localized Image Embeddings
## HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Holistic Embedding Module, Multi-Stage Training Strategy, Instruction-Tuning
## VideoGLaMM : A Large Multimodal Model for Pixel-Level Visual Grounding in Videos
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Pixel-Level Grounding, Spatio-Temporal Decoder, Vision-Language Alignment
## FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models
- **Tags:** Medical Image Analysis, Vision-Language Models (VLMs), Quantitative Measurement Correction, Radiology Report Generation, Hallucination Mitigation
## Magma: A Foundation Model for Multimodal AI Agents
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Spatial Intelligence, Set of Marks (SoM), Trace of Mark (ToM)
## Semantic and Sequential Alignment for Referring Video Object Segmentation
- **Tags:** Referring Image Segmentation, Vision-Language Models (VLMs), Semantic Segmentation, Trajectory-to-Instance Enhancement, Semantic Gap Bridging, Low Computational Cost
- **Link:** [Link](https://github.com/anonymous61888/SSA)

## Beyond Words: Augmenting Discriminative Richness via Diffusions in Unsupervised Prompt learning
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Diffusion Models, Pseudo-labeling, Semantic-Visual Alignment, High-Fidelity Synthetic Samples, Robust Image-Image-Pair Classification, Semantic-Visual Alignment Enhancement
## Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves
- **Tags:** Vision-Language Models (VLMs), Knowledge Distillation, Layer-wise Skipping, Class-wise Skipping, Feature-gradient Propagation
- **Link:** [Link](https://github.com/anonymity-007/SkipT)

## ATP-LLaVA: Adaptive Token Pruning for Large Vision Language Models
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Adaptive Token Pruning, Spatial Augmented Pruning, Instance-Specific Pruning
## Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding
- **Tags:** Vision-Language Models (VLMs), 3D Reconstruction, Spherical Geometry, Hyperbolic Geometry, Mixture-of-Experts
## Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key
- **Tags:** Vision-Language Models (VLMs), Data Augmentation, Direct Preference Optimization (DPO), On-Policy Alignment, Hallucination Mitigation
## Interleaved-modal Chain-of-Thought
- **Tags:** Vision-Language Models (VLMs), Chain-of-Thought (CoT), Attention-driven Selection (ADS), Multimodal Reasoning, Interpretability
## Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention
- **Tags:** Vision-Language Models (VLMs), Object Hallucinations, Attention Mechanisms, Image-Prompt Matching, Logit Calibration
## FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Robust Fine-Tuning, Mahalanobis Distance, Multi-Modal Distribution Shifts
## Visual and Semantic Prompt Collaboration for Generalized Zero-Shot Learning
- **Tags:** Zero-Shot Learning, Vision-Language Models (VLMs), Prompt Tuning, Visual-Semantic Alignment, Feature Adaptation
## Towards General Visual-Linguistic Face Forgery Detection
- **Tags:** Vision-Language Models (VLMs), Face Forgery Detection, Multimodal Annotation, Hallucination Reduction, Forgery Mask Utilization
## Task-aware Cross-modal Feature Refinement Transformer with Large Language Models for Visual Grounding
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Cross-modal Feature Fusion, Referring Expression Comprehension, Referring Expression Segmentation
## F-LMM: Grounding Frozen Large Multimodal Models
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Visual Grounding, Attention Mechanism, Mask Refinement
## Cross-modal Information Flow in Multimodal Large Language Models
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Visual Question Answering, Modality Integration, Information Flow Analysis
## MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data with Vision Generation Task using Discrete Visual Representations
- **Tags:** Vision-Language Models (VLMs), Medical Image Analysis, Image Generation, Visual Vector Quantization, Text-Grounded Image Generation, Cross-Modal Learning
## Learning a Visual Lexicon from Diffusion Models
- **Tags:** Diffusion Models, Self-Supervised Learning, Vision-Language Models (VLMs), Text-to-Image Generation, Zero-Shot Learning, High-Fidelity Reconstruction
## Domain Generalization in CLIP via Learning with Diverse Text Prompts
- **Tags:** Domain Generalization, Vision-Language Models (VLMs), CLIP, Text Prompts, Feature Suppression, Feature Diversification
## Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model
- **Tags:** 3D Point Cloud, Vision-Language Models (VLMs), Few-Shot Learning, Pseudo-label Selection, Adaptive Infilling, Novel-Base Mix Strategy
## On the Zero-shot Adversarial Robustness of Vision-Language Models: A Truly Zero-shot and Training-free Approach
- **Tags:** Vision-Language Models (VLMs), Zero-Shot Learning, Adversarial Robustness, Gaussian Noise, Embedding Space Navigation
## BIOMEDICA: An Open Biomedical Image-Caption Archive with Vision-Language Models derived from Scientific Literature
- **Tags:** Vision-Language Models (VLMs), Medical Image Analysis, Zero-Shot Learning, Image-Text Retrieval, Biomedical Dataset
## Style Evolving along Chain-of-Thought for Unknown-Domain Object Detection
- **Tags:** Object Detection, Vision-Language Models (VLMs), Multimodal Learning, Chain-of-Thought, Style Evolution, Domain Generalization
## Context-Aware Multimodal Pretraining
- **Tags:** Multimodal Large Language Models (MLLMs), Zero-Shot Learning, Few-Shot Learning, Vision-Language Models, Metric-Based Adaptation
## Few-Shot Recognition via Stage-wise Retrieval-Augmented Finetuning
- **Tags:** Few-Shot Learning, Vision-Language Models (VLMs), Retrieval-Augmented Learning, Stage-Wise Training, Domain Adaptation
## Cross-Modal and Uncertainty-Aware Agglomeration for Open-Vocabulary 3D Scene Understanding
- **Tags:** 3D Semantic Segmentation, Vision-Language Models (VLMs), Deterministic Uncertainty Estimation, Cross-Modal Learning, Open-Vocabulary Learning
## Once-Tuning-Multiple-Variants: Tuning Once and Expanded as Multiple Vision-Language Model Variants
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Dynamic Weight Expansion, Mathematical Series Expansion, Inference Optimization
## Conical Visual Concentration for Efficient Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Data Augmentation, Token Reduction, Efficiency Optimization, Multi-modal Performance
- **Link:** [Link](https://github.com/Cooperx521/PyramidDrop)

## Building a Mind Palace: Structuring Environment-Grounded Semantic Graphs or Effective Long Video Analysis with LLMs
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Semantic Graph Construction, Spatio-Temporal Reasoning, Environment Layout Mapping
## Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks
- **Tags:** Vision-Language Models (VLMs), Adversarial Attacks, Adaptive Activation Steering, Transferable Steering Vectors, Jailbreak Mitigation
## Words or Vision: Do Vision-Language Models Have Blind Faith in Text?
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Text Bias, Modality Preference, Supervised Fine-Tuning
## Embodied Scene Understanding for Vision Language Models via MetaVQA
- **Tags:** Vision-Language Models (VLMs), Autonomous Driving, Visual-Question-Answering (VQA), Spatial Reasoning, Closed-loop Simulation, Safety-critical Applications
## Empowering Large Language Models with 3D Situation Awareness
- **Tags:** Large Language Models (LLMs), 3D Scene Understanding, Vision-Language Models (VLMs), Egocentric Perspective, Situation Grounding, 3D Scene Captioning
## ChatGarment: Garment Estimation, Generation and Editing via Large Language Models
- **Tags:** Vision-Language Models (VLMs), 3D Generation, Image Editing, GarmentCode, Interactive Editing, Multimodal Inputs
## Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Parameter-Efficient Fine-Tuning, Spurious Correlation Mitigation, Group Robustness
## EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions
- **Tags:** Large Language Models (LLMs), Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Emotionally Enhanced Speech, Omni-modal Alignment, Semantic-Acoustic Disentanglement
## SLADE: Shielding against Dual Exploits in Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Adversarial Robustness, Adversarial Fine-Tuning, Dual-Level Contrastive Learning, CLIP-Based Encoders
## Minimal Interaction Seperated Tuning: A New Paradigm for Visual Adaptation
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Data Augmentation, Lightweight Attention-Based Adaptor, Intermediate Feature Summation, Resource-Efficient Fine-Tuning
## OmniManip: Towards General Robotic Manipulation via Object-Centric Interaction Primitives as Spatial Constraints
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Object-Centric Representation, 6D Pose Tracking, Zero-Shot Generalization
## BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing
- **Tags:** 3D Generation, Vision-Language Models (VLMs), Inference Scaling, Verification Optimization, 3D Graphics Editing Benchmark
## ECBench: Can Multi-modal Foundation Models Understand the Egocentric World?  A Holistic Embodied Cognition Benchmark
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Egocentric Video Analysis, Cognitive Benchmarking, Human Annotation Strategies
## Joint Scheduling of Causal Prompts and Tasks for Multi-Task Learning
- **Tags:** Vision-Language Models (VLMs), Multi-Task Learning, Causal Intervention, Bi-Level Optimization, Task-Prompt Scheduling
## InteractVLM: 3D Interaction Reasoning from 2D Foundational Models
- **Tags:** 3D Human Pose Estimation, 3D Object Detection, Vision-Language Models (VLMs), 3D Reconstruction, Human-Object Interaction, Multi-View Localization
## V$^2$Dial: Unification of Video and Visual Dialog via Multimodal Experts
- **Tags:** Multimodal Learning, Vision-Language Models (VLMs), Conversational AI, Contrastive Learning, Domain Shift Analysis
## Is Your World Simulator a Good Story Presenter? A Consecutive Events-Based Benchmark for Future Long Video Generation
- **Tags:** Video Generation, Vision-Language Models (VLMs), Story-Oriented Benchmark, Event-Level Evaluation, Text-to-Video Models
## Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift
- **Tags:** Vision-Language Models (VLMs), Backbone, Data Augmentation, Backdoor Attacks, Domain Generalization, Multimodal Attribution
## From Head to Tail: Towards Balanced Representation in LargeÂ Vision-Language Models through Adaptive Data Calibration
- **Tags:** Vision-Language Models (VLMs), Long-Tail Learning, Data Rebalancing, Denoising Diffusion Probabilistic Models, Adaptive Data Refinement
## Distilling Spectral Graph for Object-Context Aware Open-Vocabulary Semantic Segmentation
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Spectral Graph Distillation, Zero-Shot Object Presence Likelihood, Object-Level Contextual Knowledge
## LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), 3D Generation, Differentiable Optimization, Semantic Scene Understanding, 3D Scene Generation
## STPro: Spatial and Temporal Progressive Learning for Weakly Supervised Spatio-Temporal Grounding
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Weakly Supervised Learning, Curriculum Learning, Spatio-Temporal Grounding
- **Link:** [Link](https://aaryangrg.github.io/research/stpro)

## Nullu: Mitigating Object Hallucinations in Large Vision-Language Models via HalluSpace Projection
- **Tags:** Vision-Language Models (VLMs), Object Hallucinations, HalluSpace Projection, Null Space Projection, Model Weight Editing
## Anchor-Aware Similarity Cohesion in Target Frames Enables Predicting Temporal Moment Boundaries in 2D
- **Tags:** Video Understanding, Vision-Language Models, Temporal Boundary Prediction, Semantic Similarity Space, Anchor Frame Selection
## Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method
- **Tags:** Vision-Language Models (VLMs), Autonomous Driving, Long-Horizon Planning, Dynamic Memory Integration, Automated Data Generation
## Assessing and Learning Alignment of Unimodal Vision and Language Models
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Transfer Learning, Zero-Shot Learning, Multimodal Alignment
## Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition
- **Tags:** Vision-Language Models (VLMs), Diffusion Models, Unsupervised Domain Adaptation, Emotion Recognition, Pseudo-label Generation
## VideoGEM: Training-free Action Grounding in Videos
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Self-Attention Mechanism, Dynamic Layer Weighting, Prompt Decomposition
## HalLoc: Token-level Localization of Hallucinations for Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Hallucination Detection, Token-level Annotation, Probabilistic Detection, Plug-and-Play Integration
## VisionArena: 230k Real World Image Conversations with Paired Human Preferences
- **Tags:** Vision-Language Models (VLMs), Datasets and Benchmarks, Human Preference Alignment, Crowdsourced Dataset, Automatic Benchmarking
## Personalized Preference Fine-tuning of Diffusion Models
- **Tags:** Diffusion Models, Vision-Language Models (VLMs), Personalized Preference Learning, Cross-Attention Mechanisms, Few-Shot Learning
## DVHGNN: Multi-Scale Dilated Vision HGNN for Efficient Vision Recognition
- **Tags:** Graph Neural Networks (GNNs), Vision-Language Models (VLMs), Hypergraph Neural Networks, Multi-Scale Feature Extraction, Dynamic Hypergraph Convolution
## RoboGround: Robot Manipulation with Grounded Vision-Language Priors
- **Tags:** Embodied AI, Vision-Language Models (VLMs), Grounding Masks, Robot Manipulation, Simulated Data Generation
## Preserve or Modify? Context-Aware Evaluation for Balancing Preservation and Modification in Text-Guided Image Editing
- **Tags:** Vision-Language Models (VLMs), Image Editing, Context-Aware Metrics, CLIP Space Analysis, Multi-Modal Large Language Models
## Evaluating Model Perception of Color Illusions in Photorealistic Scenes
- **Tags:** Vision-Language Models (VLMs), Datasets and Benchmarks, Color Illusion Perception, Perceptual Biases, Automated Image Generation
## Self-Evolving Visual Concept Library using Vision-Language Critics
- **Tags:** Vision-Language Models (VLMs), Zero-Shot Learning, Self-Evolving Systems, Concept Library Learning, Automated Visual Recognition
## Vision-Language Models Do Not Understand Negation
- **Tags:** Vision-Language Models (VLMs), Negation Understanding, NegBench, CLIP Fine-Tuning, Synthetic Data
## Attribute-formed Class-specific Concept Space: Endowing Language Bottleneck Model with Better Interpretability and Scalability
- **Tags:** Vision-Language Models (VLMs), Zero-Shot Learning, Concept Bottleneck Models, Few-Shot Learning, Automatic Concept Generation
## Robotic Visual Instruction
- **Tags:** Vision-Language Models (VLMs), Robotic Control, 2D-to-3D Transformation, Keypoint Extraction, Edge Deployment
## BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Biomedical Image Analysis, Prompt Learning, Few-Shot Learning, Knowledge Distillation
## SVLTA: Benchmarking Vision-Language Temporal Alignment via Synthetic Video Situation
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Temporal Alignment, Synthetic Data Generation, Compositional Benchmarking
## RADIO Amplified: Improved Baselines for Agglomerative Vision Foundation Models
- **Tags:** Vision-Language Models (VLMs), Knowledge Distillation, Multi-Teacher Distillation, Token Compression, Resolution Mode Shifts
## Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Directed Scene Graph, Detailed Captioning, Compositional Information
## ProAPO: Progressively Automatic Prompt Optimization for Visual Classification
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Prompt Optimization, Evolution-Based Algorithm, One-Shot Classification
- **Link:** [Link](https://anonymous.4open.science/r/ProAPO)

## VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Chain-of-Thought (CoT), Core Frame Selection, Hybrid LVLMs Collaboration
## Dual-Granularity Semantic Guided Sparse Routing Diffusion Model for General Pansharpening
- **Tags:** Pansharpening, Vision-Language Models (VLMs), Dynamic Sparse Routing, Dual-Granularity Semantics, Satellite Image Processing
## Bayesian Test-Time Adaptation for Vision-Language Models
- **Tags:** Vision-Language Models, Zero-Shot Learning, Bayesian Inference, Test-Time Adaptation, Distribution Shift Adaptation
## One-shot 3D Object Canonicalization based on Geometric and Semantic Consistency
- **Tags:** 3D Object Canonicalization, Large Language Models (LLMs), Vision-Language Models (VLMs), Semantic Consistency, Geometric Consistency, One-shot Learning
## Unlocking Video-LLM via Agent-of-Thoughts Distillation
- **Tags:** Video Understanding, Vision-Language Models (VLMs), Chain-of-Thoughts (CoTs), Agent-Based Systems, Instruction-Tuning
## A3: Few-shot Prompt Learning of Unlearnable Examples with Cross-Modal Adversarial Feature Alignment
- **Tags:** Few-shot Learning, Vision-Language Models (VLMs), Adversarial Feature Alignment, Data Protection, Cross-Modal Learning
## Efficient Transfer Learning for Video-language Foundation Models
- **Tags:** Vision-Language Models (VLMs), Zero-Shot Learning, Video Understanding, Spatio-Temporal Adapter, Consistency Constraint, Parameter Efficiency
## Multimodal Autoregressive Pre-training of Large Vision Encoders
- **Tags:** Multimodal Large Language Models (MLLMs), Vision-Language Models (VLMs), Autoregressive Pre-training, Multimodal Decoder, Scalable Vision Encoders
## ICT: Image-Object Cross-Level Trusted Intervention for Mitigating Object Hallucination in Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Object Hallucination, Attention Mechanism, Training-Free Intervention, Visual Detail Enhancement
## Cropper: Vision-Language Model for Image Cropping through In-Context Learning
- **Tags:** Vision-Language Models (VLMs), Image Editing, In-Context Learning, Prompt Retrieval, Iterative Refinement
## Uni4D: Unifying Large Vision Models for 4D Modeling from a Single Video
- **Tags:** 4D Modeling, Dynamic Scene Understanding, Vision-Language Models, 3D Reconstruction, Camera Pose Estimation, Multi-Stage Optimization, Pretrained Model Integration, Dynamic 3D Motion Tracking
## PVC: Progressive Visual Token Compression for Unified Image and Video Processing in Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Data Augmentation, Token Compression, Temporal Redundancy, Unified Processing
- **Link:** [Link](https://github.com/OpenGVLab/PVC)

## LOGICZSL: Exploring Logic-induced Representation for Compositional Zero-shot Learning
- **Tags:** Zero-Shot Learning, Vision-Language Models (VLMs), Logic Rules, Semantic Relationships, Compositional Learning
## JarvisIR: Elevating Autonomous Driving Perception with Intelligent Image Restoration
- **Tags:** Autonomous Driving, Low-Level Vision, Vision-Language Models (VLMs), Data Augmentation, Unsupervised Learning, Real-World Data Handling, Instruction-Response Dataset
## DocVLM: Make Your VLM an Efficient Reader
- **Tags:** Vision-Language Models (VLMs), Optical Character Recognition (OCR), Document Understanding, Efficiency Optimization, Zero-Shot Learning
## BOLT: Boost Large Vision-Language Model Without Training for Long-form Video Understanding
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Frame Selection Strategies, Inverse Transform Sampling, Multi-Source Retrieval
## Black Swan: Abductive and Defeasible Video Reasoning in Unexpected Events
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Abductive Reasoning, Defeasible Reasoning, Unexpected Event Reasoning, Benchmark Evaluation, Commonsense Reasoning
## Overcoming Shortcut Problem in VLM for Robust Out-of-Distribution Detection
- **Tags:** Vision-Language Models (VLMs), Out-of-Distribution Detection, Background Decoupling, Mask-Guided Regularization, Pseudo-OOD Supervision
## Dual Semantic Guidence for Open Vocabulary Semantic Segmentation
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Dual Semantic Guidance, Pixel-level Pseudo Annotations, Foreground-Background Separation
## Enhancing Vision-Language Compositional Understanding with Multimodal Synthetic Data
- **Tags:** Vision-Language Models (VLMs), Data Augmentation, Text-to-Image Generation, Adaptive Margin Loss, Compositional Understanding
## Feat2GS: Probing Visual Foundation Models with Gaussian Splatting
- **Tags:** 3DGS (Gaussian Splatting), Vision-Language Models (VLMs), 3D Awareness, Novel-View Synthesis, Texture Awareness
## Language-Guided Salient Object Ranking
- **Tags:** Vision-Language Models (VLMs), Salient Object Ranking (SOR), Multimodal Graph Learning, Text-Guided Visual Modulation, Text-Aware Visual Reasoning
## MMRL: Multi-Modal Representation Learning for Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Few-Shot Learning, Modality-Agnostic Representation, Regularization for Generalization
## Explain in Diffusion: Explaining a Classifier with Diffusion Semantics
- **Tags:** Diffusion Models, Vision-Language Models (VLMs), Classifier Explainability, Training-Free Framework, Hierarchical Semantic Corpus
## F^3OCUS - Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics
- **Tags:** Vision-Language Models (VLMs), Federated Learning, Parameter-Efficient Fine-Tuning (PEFT), Meta-Heuristic Optimization, Neural Tangent Kernels
## Explainable Saliency: Articulating Reasoning with Contextual Prioritization
- **Tags:** Vision-Language Models (VLMs), Saliency Prediction, Explainable AI, Contextual Prioritization, Saliency Maps
## Font-Agent: Enhancing Font Understanding with Large Language Models
- **Tags:** Vision-Language Models (VLMs), Data Augmentation, Edge Aware Traces (EAT), Dynamic Direct Preference Optimization (D-DPO), Font Quality Assessment
## Advancing Myopia To Holism: Fully Contrastive Languageâ€“Image Pre-training
- **Tags:** Vision-Language Models (VLMs), Contrastive Language-Image Pre-training (CLIP), Multi-Text Generation, Multi-Branch Image Encoder, Part-to-Part Matching
## EarthDial: Turning Multi-sensory Earth Observations to Interactive Dialogues
- **Tags:** Vision-Language Models (VLMs), Remote Sensing Image Analysis, Multi-sensory Data Integration, Instruction Tuning, Change Detection
## A Stitch in Time Saves Nine: Small VLM is a Precise Guidance for accelerating Large VLMs
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Attention Mechanisms, Token Pruning, Early Exiting Mechanism
## Discriminative Fine-tuning of LVLMs
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Discriminative Fine-tuning, LoRA Adapters, Compositionality
## Re-thinking Temporal Search for Long-Form Video Understanding
- **Tags:** Video Understanding, Vision-Language Models (VLMs), Temporal Search, Keyframe Selection, Adaptive Zooming
## VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Knowledge Distillation, Layer-wise Distillation, Intermediate Verbalizers, Efficient VLMs
## SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model
- **Tags:** Vision-Language Models (VLMs), Datasets and Benchmarks, Safety Alignment, Preference Learning, Multimodal Safety
## SAMWISE: Infusing wisdom in SAM2 for Text-Driven Video Segmentation
- **Tags:** Referring Image Segmentation, Vision-Language Models (VLMs), Video Understanding, Temporal Modeling, Streaming Video Processing, Tracking Bias Correction
## Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Robotic Manipulation, Multi-Modal Prompts, SE(3) Space Prediction, Long-Horizon Task Execution
## Explaining Domain Shifts in Language: Concept Erasing for Interpretable Image Classification
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Domain Generalization, Concept Erasing, Interpretable AI
## Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection
- **Tags:** Vision-Language Models (VLMs), Autonomous Driving, Spatio-temporal Constraints, Real-time Monitoring, Constraint-aware Visual Programming
## Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark
- **Tags:** Document Image Retrieval, Vision-Language Models (VLMs), Natural Language Queries, Fine-Grained Semantic Retrieval, Contrastive Learning
## CoLLM: A Large Language Model for Composed Image Retrieval
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Composed Image Retrieval, Multimodal Fusion, Dataset Generation
## PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Prompt Sensitivity Analysis, Model Reliability Score, Training Data Impact
## g3D-LF: Generalizable 3D-Language Feature Fields for Embodied Tasks
- **Tags:** Embodied AI, 3D Reconstruction, Vision-Language Models (VLMs), Multimodal Learning, Novel View Synthesis, BEV Maps, Multi-Granularity Language Querying
## Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields
- **Tags:** 3DGS (Gaussian Splatting), Vision-Language Models (VLMs), 4D Feature Fields, Dynamic Scene Interaction, Monocular Video Processing
## SocialGesture: Delving into Multi-person Gesture Understanding
- **Tags:** Multimodal Learning, Vision-Language Models (VLMs), Multi-person Interaction Analysis, Gesture Recognition, Visual Question Answering
## Beyond Sight: Towards Cognitive Alignment in LVLM via Enriched Visual Knowledge
- **Tags:** Vision-Language Models (VLMs), Large Language Models (LLMs), Cognitive Misalignment, Entity-Enhanced Cognitive Alignment (EECA), Multi-Granularity Supervision
## SceneTAP: Scene-Coherent Typographic Adversarial Planner against Vision-Language Models in Real-World Environments
- **Tags:** Vision-Language Models (VLMs), Adversarial Attacks, Scene-Coherent Adversarial Planning, TextDiffuser, Chain-of-Thought Reasoning
## Interpreting Object-level Foundation Models via Visual Precision Search
- **Tags:** Vision-Language Models (VLMs), Object Detection, Interpretability, Attribution Maps, Visual-Textual Fusion
## Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models
- **Tags:** Self-Supervised Learning, Vision-Language Models, Backdoor Attack, Security, Trigger Optimization, Visual Hallucination, Trigger Optimization, Backdoor Learning
## Continual SFT Matches Multimodal RLHF with Negative Supervision
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Negative Supervision, Memory Efficiency, Preference Alignment
## SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting
- **Tags:** Vision-Language Models (VLMs), Test-Time Adaptation (TTA), Transductive Learning, Attribute Prompting, Domain Adaptation
## Adaptive Parameter Selection for Tuning Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Parameter-efficient fine-tuning (PEFT), Adaptive Learning Rate, Few-Shot Learning, Out-of-Distribution Generalization
## Itâ€™s a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data
- **Tags:** Vision-Language Models (VLMs), Self-Supervised Learning, Unsupervised Learning, Quadratic Assignment Problem, Semantic Embedding
## STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Anomaly Detection, X-ray Security, Visual AI Assistant, Cross-Domain Generalization
## JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation
- **Tags:** Multimodal Large Language Models (MLLMs), Image Generation, Rectified Flow, Unified Vision-Language Models, Autoregressive Language Models
## Identifying and Mitigating Position Bias of Multi-image Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Position Bias, Attention Mechanisms, Training-Free Methods
## OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counter Factual Reasoning
- **Tags:** Vision-Language Models (VLMs), Autonomous Driving, Counterfactual Reasoning, 3D Perception, Synthetic Data Annotation
## Recover and Match: Open-Vocabulary Multi-Label Recognition through Knowledge-Constrained Optimal Transport
- **Tags:** Vision-Language Models (VLMs), Open-Vocabulary Multi-Label Recognition, Optimal Transport, Local Semantics Recovery, Multi-Domain Performance
## 5%>100%: Breaking Performance Shackles of Full Fine-Tuning on Visual Recognition Tasks
- **Tags:** Vision-Language Models (VLMs), Object Detection, Semantic Segmentation, Adapter-based Tuning, Scaled Layernorm, Vision-Friendly Filters
- **Link:** [Link](https://github.com/Leiyi-Hu/mona)

## Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Few-Shot Learning, Meta-Learning, LoRA Recycle, Tuning-Free Adaptation, Meta-LoRA
## DepthCues: Evaluating Monocular Depth Perception in Large Vision Models
- **Tags:** Depth Estimation, Vision-Language Models (VLMs), Monocular Depth Cues, Benchmark Development, Fine-Tuning for Depth Perception
## SOLAMI: Social Vision-Language-Action Modeling for Immersive Interaction with 3D Autonomous Characters
- **Tags:** Avatars, Vision-Language Models (VLMs), 3D Reconstruction, Multimodal Learning, Social Intelligence, VR Interaction, Multimodal Response Generation
## ILIAS: Instance-Level Image retrieval At Scale
- **Tags:** Instance-Level Image retrieval, Datasets and Benchmarks, Large-Scale Retrieval, Vision-Language Models, Local Descriptors
## UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning
- **Tags:** Few-Shot Learning, Transductive Learning, Learning to Optimize, Hyper-parameter Optimization, Vision-Language Models
- **Link:** [Link](https://anonymous.4open.science/r/UNEM)

## Open-Vocabulary Functional 3D Scene Graphs for Real-World Indoor Spaces
- **Tags:** 3DGS (Gaussian Splatting), Vision-Language Models (VLMs), Functional 3D Scene Graphs, Indoor Scene Understanding, Robotic Manipulation
## COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation
- **Tags:** Vision-Language Models (VLMs), Test-Time Adaptation, Dual Semantics Graph, Clique Guided Hyper-class, Cross-Modal Semantic Caching
## DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception
- **Tags:** Vision-Language Models (VLMs), Semantic Segmentation, Open-Vocabulary Learning, Self-Attention Decoupling, Local Feature Enhancement
## Octopus: Alleviating Hallucination via Dynamic Contrastive Decoding
- **Tags:** Vision-Language Models (VLMs), Contrastive Decoding, Dynamic Decoding, Hallucination Mitigation, Adaptive Framework
## VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary
- **Tags:** Video Understanding, Vision-Language Models (VLMs), Generative Retrieval Model, Hierarchical Vocabulary, Vocabulary Update Strategy
## Contextual AD Narration with Interleaved Multimodal Sequence
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Multimodal Learning, Character-Refinement Module, Contrastive Loss
## ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Object Segmentation, Real-Time Object Tracking, Spatial Reasoning
## DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Token Compression, KV Cache Reduction, Training-Free Optimization
## Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM
- **Tags:** Vision-Language Models (VLMs), Test-Time Adaptation (TTA), Online EM Algorithm, Zero-Shot Predictions, Distributional Modeling
## Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Compositionality, Geodesically Decomposable Embeddings (GDE), Group Robustness, Latent Space Geometry
## Libra-Merging: Importance-redundancy and Pruning-merging Trade-off for Acceleration Plug-in in Large Vision-Language Model
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Token Compression, Information Compensation, Plug-in Acceleration
## Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning
- **Tags:** Vision-Language Models (VLMs), Data Augmentation, Instruction Generation, Task-Wise Sampling, Image Clustering
## Dynamic Updates for Language Adaptation in Visual-Language Tracking
- **Tags:** Vision-Language Models (VLMs), Visual Tracking, Dynamic Language Update, Dynamic Template Capture, Multi-modal Reference Update
## VisionZip: Longer is Better but Not Necessary in Vision Language Models
- **Tags:** Vision-Language Models (VLMs), Data Augmentation, Token Selection, Inference Speed Optimization, Visual Feature Extraction
## Learning Visual Composition through Improved Semantic Guidance
- **Tags:** Vision-Language Models (VLMs), Contrastive Learning, Compositional Learning, Weakly Supervised Learning, Image Retrieval
## Towards Understanding How Knowledge Evolves in Large Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Multimodal Learning, Knowledge Evolution, Critical Layers, Mutation Layers
## VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents
- **Tags:** Retrieval-Augmented Generation (RAG), Vision-Language Models (VLMs), Document Understanding, Visual Question Answering, Self-Supervised Learning
## Not Just Text: Uncovering Vision Modality Threats in Image Generation Models
- **Tags:** Text-to-Image Generation, Image Editing, Vision-Language Models (VLMs), Typographic Attack, Security Threats, Visual Modality Vulnerability
## Mono3DVLT: Monocular-Video-Based 3D Visual Language Tracking
- **Tags:** Visual Tracking, 3D Object Tracking, Vision-Language Models (VLMs), Monocular Video, Natural Language Descriptions, Multi-Modal Feature Extraction
## Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation
- **Tags:** Vision-Language Models (VLMs), Datasets and Benchmarks, Automated Question Generation, Multiple-Choice Question Evaluation, VLM Benchmarking
## Unveiling the Mist over 3D Vision-Language Understanding: Object-centric Evaluation with Chain-of-Analysis
- **Tags:** Vision-Language Models (VLMs), 3D Point Cloud, Large Language Models (LLMs), Object-centric Evaluation, Chain-of-Analysis, 3D-VL Benchmark
## ReWind: Understanding Long Videos with Instructed Learnable Memory
- **Tags:** Vision-Language Models (VLMs), Video Understanding, Dynamic Memory, Cross-Attention Mechanisms, Temporal Grounding
## LSceneLLM: Enhancing Large 3D Scene Understanding Using Adaptive Visual Preferences
- **Tags:** 3DGS (Gaussian Splatting), Vision-Language Models (VLMs), Adaptive Visual Preferences, Scene Magnifier Module, Cross-Room Understanding Benchmark
- **Link:** [Link](https://arxiv.org/abs/2412.01292)

## FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts
- **Tags:** 3D Generation, Vision-Language Models (VLMs), Graph-aware Denoising, Mixed Graph Diffusion Transformer, User-friendly Scene Synthesis
## Devils in Middle Layers of Large Vision-Language Models: Interpreting, Detecting and Mitigating Object Hallucinations via Attention Lens
- **Tags:** Vision-Language Models (VLMs), Object Detection, Attention Mechanisms, Attention Patterns, Inference-Time Optimization, Visual Information Processing
- **Link:** [Link](https://anonymous.4open.science/r/middlelayersindicating_hallucinations-C45A)

## Noise Diffusion for Enhancing Semantic Faithfulness in Text-to-Image Synthesis
- **Tags:** Diffusion Models, Vision-Language Models (VLMs), Noise Diffusion, Semantic Alignment, Latent Optimization
## Joint Vision-Language Social Bias Removal for CLIP
- **Tags:** Vision-Language Models (VLMs), Social Bias Removal, Multimodal Learning, Debiasing Framework, Evaluation Protocol
## ReasonGrounder: LVLM-Guided Hierarchical Feature Splatting for Open-Vocabulary 3D Visual Grounding and Reasoning
- **Tags:** 3DGS (Gaussian Splatting), Vision-Language Models (VLMs), Open-Vocabulary Learning, Amodal Perception, 3D Scene Understanding
## Rethinking Few-Shot Adaptation of Vision-Language Models in Two Stages
- **Tags:** Vision-Language Models (VLMs), Few-Shot Learning, Parameter-Efficient Fine-tuning (PEFT), Selective Inference, Linear Classifier Optimization
## Improving Personalized Search with Regularized Low-Rank Parameter Updates
- **Tags:** Vision-Language Models (VLMs), Personalized Search, Low-Rank Adaptation, Parameter Addition, Personalized Image Retrieval
## Visual Persona: Foundation Model for Full-Body Human Customization
- **Tags:** Text-to-Image Generation, Diffusion Models, Vision-Language Models (VLMs), Full-Body Human Customization, Transformer Encoder-Decoder, Dense Identity Embeddings
## SPARC: Score Prompting and Adaptive Fusion for Zero-Shot Multi-Label Recognition in Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Zero-Shot Learning, Multimodal Learning, Score Prompting, Adaptive Fusion, Debiasing Algorithm
## Hyperbolic Safety-Aware Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Safety-Aware AI, Hyperbolic Space, Entailment Hierarchy, Content Moderation
## Unbiasing through Textual Descriptions: Mitigating Representation Bias in Video Benchmarks
- **Tags:** Video Understanding, Vision-Language Models (VLMs), Large Language Models (LLMs), Bias Mitigation, Video Benchmarking, Textual Description Analysis
## Diffusion Bridge: Leveraging Diffusion Model to Reduce the Modality Gap Between Text and Vision for Zero-Shot Image Captioning
- **Tags:** Diffusion Models, Zero-Shot Learning, Vision-Language Models (VLMs), Cross-Modal Alignment, Denoising Diffusion Probabilistic Models (DDPM), Text-Vision Embedding Refinement
## SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding
- **Tags:** Vision-Language Models (VLMs), Medical Image Analysis, Whole-Slide Image Analysis, Instruction-Following Dataset, Multimodal Benchmark
## COAP: Memory-Efficient Training with Correlation-Aware Gradient Projection
- **Tags:** Memory-Efficient Training, Gradient Projection, Large Language Models (LLMs), Vision-Language Models (VLMs), 8-bit Quantization, Correlation-Aware Optimization, Low-Rank Projection
## AnyAttack: Targeted Adversarial Attacks on Vision-Language Models Toward Any Images
- **Tags:** Vision-Language Models (VLMs), Adversarial Attacks, Self-Supervised Learning, Transferability, Multimodal Tasks
## SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation
- **Tags:** Semantic Segmentation, Domain Adaptation, Semi-supervised Learning, Vision-Language Models (VLMs), Long-Tail Learning, Language Guidance, Class-Balanced Loss, Semantic Generalization
## MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output
- **Tags:** Vision-Language Models (VLMs), Medical Image Analysis, Multimodal Learning, Visual Referring, Pixel Grounding, Medical Multimodal Dataset
## Exploring Visual Vulnerabilities via Multi-Loss Adversarial Search for Jailbreaking Vision-Language Models
- **Tags:** Vision-Language Models (VLMs), Adversarial Attacks, Scenario-Aware Image Generation, Flat Minima Theory, Multi-Image Collaborative Attacks
## Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels
- **Tags:** Vision-Language Models (VLMs), Object Detection, Pixel-Level Grounding, Instruction-Following Data, Visual-Language Knowledge Distillation
## SimLingo: Vision-only Closed-Loop Autonomous Driving with Grounded Language Understanding
- **Tags:** Autonomous Driving, Vision-Language Models (VLMs), Language-Action Alignment, Closed-Loop Driving, Camera-Only Systems
## PhysVLM: Enabling Visual Language Models to Understand Robotic Physical Reachability
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Robotic Physical Reachability, Space-Physical Reachability Map (S-P Map), Multi-Robot Dataset
- **Link:** [Link](https://github.com/unira-zwj/PhysVLM)

## GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Pose2CLIP, Iterative Reward Design, Open-Vocabulary Learning
## Dual Diffusion for Unified Image Generation and Understanding
- **Tags:** Diffusion Models, Vision-Language Models (VLMs), Multimodal Diffusion Transformer, Cross-Modal Maximum Likelihood Estimation, Unified Vision-Language Modeling
## Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation
- **Tags:** Multimodal Learning, Vision-Language Models (VLMs), Autoregressive Framework, Visual Encoding Decoupling, Unified Transformer Architecture
## FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image Pre-training
- **Tags:** Large Language Models (LLMs), Vision-Language Models (VLMs), Prompt Distillation, Facet-Decoupled Attention, Multilingual Generalization
