# **Embodied AI - Full Paper Collection**

## MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation
- **Tags:** Embodied AI, Vision-Language Models (VLMs), Policy Adaptation, Bi-level Optimization, Trajectory Generation
## ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping
- **Tags:** 3D Reconstruction, Embodied AI, Occlusion Reasoning, Spatial Relationship Modeling, Synthetic Dataset
## BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence
- **Tags:** Embodied AI, 3D Object Detection, Image-Centric 3D Perception, Multi-Modal Feature Fusion, Spatial Enhancer Module
## Mitigating the Human-Robot Domain Discrepancy in Visual Pre-training for Robotic Manipulation
- **Tags:** Embodied AI, Self-Supervised Learning, Contrastive Learning, Domain Adaptation, Robotic Manipulation
## ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning
- **Tags:** Embodied AI, 3D Reconstruction, Residual Learning, Bimanual Manipulation, Dexterous Robotic Hands
## VidBot: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation
- **Tags:** Embodied AI, Zero-Shot Learning, 3D Reconstruction, Diffusion Models, 3D Hand Trajectories, Coarse-to-Fine Learning, Context-Aware Interaction Planning
- **Link:** [Link](https://hanzhic.github.io/vidbot-project/)

## Physical Plausibility-aware Trajectory Prediction via Locomotion Embodiment
- **Tags:** Embodied AI, Human Action Prediction, Differentiable Physics Simulation, Stochastic HTP Network, Locomotion Value Filter
## Vision-Language Embodiment for Monocular Depth Estimation
- **Tags:** Depth Estimation, Embodied AI, Vision-Language Models (VLMs), Monocular Depth Estimation, Camera Model Integration, Text-Image Fusion
## Scene Map-based Prompt Tuning for Navigation Instruction Generation
- **Tags:** Embodied AI, Large Language Models (LLMs), 3D Voxel Encoding, Topological Map Integration, Landmark Uncertainty Assessment
## RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation
- **Tags:** Embodied AI, 3D Reconstruction, Video-Instruction Tuning, Open-World Navigation, Zero-Shot Learning
## Decision SpikeFormer: Spike-Driven Transformer for Decision Making
- **Tags:** Embodied AI, Spiking Neural Networks (SNNs), Temporal Spiking Self-Attention, Progressive Threshold-dependent Batch Normalization, Offline Reinforcement Learning
## Collaborative Tree Search for Enhancing Embodied Multi-Agent Collaboration
- **Tags:** Embodied AI, Large Language Models (LLMs), Monte Carlo Tree Search, Plan Evaluation Module, Multi-Agent Collaboration
## 3D-MVP: 3D Multiview Pretraining for Robotic Manipulation
- **Tags:** 3D Reconstruction, Embodied AI, Masked Autoencoders, Robotic View Transformer, 3D Scene Understanding
## Point-Level Visual Affordance Guided Retrieval and Adaptation for Cluttered Garments Manipulation
- **Tags:** Embodied AI, 3D Point Cloud, Point-Level Affordance, Garment Manipulation, Adaptation Module
## EgoLife: Towards Egocentric Life Assistant
- **Tags:** Embodied AI, Multimodal Learning, Egocentric Video Understanding, Long-Context Question Answering, Wearable AI
## Reasoning in visual navigation of end-to-end trained agents: a dynamical systems approach
- **Tags:** Embodied AI, Visual Navigation, Latent Memory, Value Function, Real-World Robotics
- **Link:** [Link](https://visual-navigation-reasoning.github.io)

## Spatial-Temporal Graph Diffusion Policy with Kinematics Modeling for Bimanual Robotic Manipulation
- **Tags:** Embodied AI, Graph Neural Networks (GNNs), Bimanual Manipulation, Differentiable Kinematics, Dynamic Spatial-Temporal Graph
## Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions
- **Tags:** Embodied AI, 3D Object Detection, Vision-Language Models (VLMs), 3D Affordance Grounding, Multi-Modal Fusion, Cognitive Science
## Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation
- **Tags:** Embodied AI, Self-Supervised Learning, Primitive Prompt Learning, Lifelong Learning, Knowledge Transfer
## Ego4o: Egocentric Human Motion Capture and Understanding from Multi-Modal Input
- **Tags:** Avatars, Embodied AI, Motion VQ-VAE, Multi-modal LLM, Egocentric Motion Capture
## EgoLM: Multi-Modal Language Model of Egocentric Motions
- **Tags:** Multimodal Large Language Models (MLLMs), Embodied AI, Egocentric Motion Understanding, Wearable Devices, Motion-Language Integration
## CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Visual Chain-of-Thought Reasoning, Autoregressive Frame Prediction, Sensorimotor Control
## DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with Physics Awareness
- **Tags:** Embodied AI, Diffusion Models, Dexterous Grasping, Physics-Aware Models, Robotic Manipulation
## GUI-Xplore: Empowering Generalizable GUI Agents with One Exploration
- **Tags:** Embodied AI, Datasets and Benchmarks, Graph-Guided Reasoning, Action-aware Modeling, Cross-application Generalization
## CityWalker: Learning Embodied Urban Navigation from Web-Scale Videos
- **Tags:** Embodied AI, Autonomous Driving, Imitation Learning, Urban Navigation, Data-Driven Approach
## AffordDP: Generalizable Diffusion Policy with Transferable Affordance
- **Tags:** Diffusion Models, Embodied AI, 3D Point Cloud, 6D Object Pose Estimation, Generalization, Affordance Modeling, 6D Transformation, Action Space Manifold
## Object-Shot Enhanced Grounding Network for Egocentric Video
- **Tags:** Embodied AI, Video Understanding, Object-Shot Enhancement, Modality Alignment, Attention Information Extraction
## 3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination
- **Tags:** 3D Point Cloud, Large Language Models (LLMs), Embodied AI, Sim-to-Real Transfer, Hallucination Reduction, Instruction Tuning
## METASCENES: Towards Automated Replica Creation for Real-world 3D Scans
- **Tags:** Embodied AI, 3D Reconstruction, Datasets and Benchmarks, Multi-modal Alignment, Sim-to-Real Transfer, Object-Level Modeling
## RoboSense: Large-scale Dataset and Benchmark for Egocentric Robot Perception and Navigation in Crowded and Unstructured Environments
- **Tags:** Embodied AI, 3D Object Detection, Egocentric Perception, Multimodal Dataset, Near-Field 3D Perception
## FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation
- **Tags:** Embodied AI, 3D Generation, Conditional Flow Matching, Dynamic Radius Schedule, State Space Models
## GenManip: A Simulation Platform for Generalizable TableTop Manipulation in the Era of MLLM
- **Tags:** Embodied AI, Multimodal Large Language Models (MLLMs), Task-Oriented Scene Graphs, Policy Generalization, Human-in-the-Loop Correction
## Interactive Affordance Learning for Articulated Objects in 3D Environments
- **Tags:** 3DGS (Gaussian Splatting), Embodied AI, Articulated Object Understanding, Interactive Affordance Estimation, 3D Scene Refinement
## Functionality understanding and segmentation in 3D scenes
- **Tags:** 3D Semantic Segmentation, Embodied AI, Chain-of-Thought Reasoning, Training-Free Models, Open-Vocabulary Segmentation
## CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation
- **Tags:** Embodied AI, Datasets and Benchmarks, Manual-based Manipulation, CAD Model Integration, Robotic Task Planning
## From Multimodal LLMs to Generalist Embodied Agents: Methods and Lessons
- **Tags:** Multimodal Large Language Models (MLLMs), Embodied AI, Generalist Embodied Agent (GEA), Online Reinforcement Learning, Cross-domain Generalization
## Tartan IMU: A Light Foundation Model for Inertial Positioning in Robotics
- **Tags:** Embodied AI, 3D Reconstruction, Low-Rank Adaptation (LoRA), Online Test-Time Adaptation, Real-Time Learning
## TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization
- **Tags:** Embodied AI, 3D Generation, Tokenization, Proprioception, Unified Policy Network
## OmniManip: Towards General Robotic Manipulation via Object-Centric Interaction Primitives as Spatial Constraints
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Object-Centric Representation, 6D Pose Tracking, Zero-Shot Generalization
## ECBench: Can Multi-modal Foundation Models Understand the Egocentric World?  A Holistic Embodied Cognition Benchmark
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Egocentric Video Analysis, Cognitive Benchmarking, Human Annotation Strategies
## Two by Two: Learning Cross-Task Pairwise Objects Assembly for Generalizable Robot Manipulation
- **Tags:** 3D Reconstruction, Embodied AI, SE(3) Pose Estimation, Equivariant Geometric Features, Pairwise Object Assembly
## PDFactor: Learning Tri-Perspective View Policy Diffusion Field for Multi-Task Robotic Manipulation
- **Tags:** Embodied AI, 3D Point Cloud, Diffusion Models, Triplane Representation, 6-DoF Action Modeling, Multi-Task Policy Learning
## PhaseScene : Dynamic Scene Generation  with Phase-Specific Action Modeling for Embodied AI
- **Tags:** Embodied AI, Diffusion Models, Dynamic Scene Generation, Phase-Specific Action Modeling, Robotic Manipulation Data
## Optimus-2: Mulitimodal Minecraft Agent with Goal-Observation-Action Conditioned Policy
- **Tags:** Multimodal Large Language Models (MLLMs), Embodied AI, Goal-Observation-Action Conditioned Policy, Minecraft Goal-Observation-Action Dataset, Action-guided Behavior Encoder
## Lift3D Policy: Lifting 2D Foundation Models for Robust 3D Robotic Manipulation
- **Tags:** 3D Reconstruction, Embodied AI, Masked Autoencoder, Point Cloud Encoding, Spatial Geometry Preservation
## RoboGround: Robot Manipulation with Grounded Vision-Language Priors
- **Tags:** Embodied AI, Vision-Language Models (VLMs), Grounding Masks, Robot Manipulation, Simulated Data Generation
## Universal Actions for Enhanced Embodied Foundation Models
- **Tags:** Embodied AI, Large Language Models (LLMs), Universal Action Space, Cross-Embodiment Generalization, Robot Adaptation
## SnapMem: Snapshot-based 3D Scene Memory for Embodied Exploration and Reasoning
- **Tags:** Embodied AI, 3D Reconstruction, Memory Snapshots, Frontier Snapshots, Lifelong Memory Management
## GaPT-DAR: Category-level Garments Pose Tracking via Integrated 2D Deformation and 3D Reconstruction
- **Tags:** 3D Reconstruction, Avatars, Embodied AI, 2D Deformation, 3D-2D Projection, Depth Reconstruction
## Towards Autonomous Micromobility through Scalable Urban Simulation
- **Tags:** Embodied AI, Autonomous Driving, Robot Learning, Urban Simulation, Micromobility
## Towards Precise Embodied Dialogue Localization via Causality Guided Diffusion
- **Tags:** Embodied AI, Diffusion Models, Causal Learning, Denoising Network, Coordinate Regression
## Neural Motion Simulator Pushing the Limit of World Models in Reinforcement Learning
- **Tags:** Embodied AI, Reinforcement Learning, World Models, Long-Horizon Prediction, Zero-Shot Reinforcement Learning
## FIction: 4D Future Interaction Prediction from Video
- **Tags:** Embodied AI, Video Understanding, 4D Interaction Prediction, Human-Object Interaction, 3D Spatial Reasoning
## CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement
- **Tags:** Embodied AI, 3D Reconstruction, Human-Object Interaction, Collaborative Robotics, Motion Retargeting
## R2C: Mapping Room to Chessboard to Unlock LLM As Low-Level Action Planner
- **Tags:** Embodied AI, Large Language Models (LLMs), Grid-based Semantic Representation, Chain-of-Thought Decision, Real-time Robot Adaptation
- **Link:** [Link](https://anonymous4cv.github.io/Room2Chessboard/)

## Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Robotic Manipulation, Multi-Modal Prompts, SE(3) Space Prediction, Long-Horizon Task Execution
## Let Humanoid Robots Go Hiking! Integrative Skill Development over Complex Trails
- **Tags:** Embodied AI, Hierarchical Reinforcement Learning (HRL), Temporal Vision Transformer, Privileged Learning, Variational Autoencoder (VAE)
## UniGraspTransformer: Simplified Policy Distillation for Scalable Dexterous Robotic Grasping
- **Tags:** Embodied AI, Knowledge Distillation, Transformer-based Networks, Reinforcement Learning, Robotic Grasping
## TANGO: Training-free Embodied AI Agents for Open-world Tasks
- **Tags:** Embodied AI, Large Language Models (LLMs), Zero-Shot Learning, Memory-Based Exploration, Open-World Task Solving
## G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation
- **Tags:** 3D Generation, Embodied AI, Diffusion Models, Semantic Flow, Pose Tracking, Digital Twin Creation
## g3D-LF: Generalizable 3D-Language Feature Fields for Embodied Tasks
- **Tags:** Embodied AI, 3D Reconstruction, Vision-Language Models (VLMs), Multimodal Learning, Novel View Synthesis, BEV Maps, Multi-Granularity Language Querying
## UniGoal: Towards Universal Zero-shot Goal-oriented Navigation
- **Tags:** Zero-Shot Learning, Embodied AI, Graph Neural Networks (GNNs), Scene Graph, Graph Matching, Zero-Shot Navigation
## ISMimic: Learning Basketball Interaction Skills from Demonstrations
- **Tags:** Embodied AI, Data Augmentation, Skill Diversity, High-Level Controller Integration, Human-Ball Motion Mimicry
- **Link:** [Link](https://ismimic.github.io)

## ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Object Segmentation, Real-Time Object Tracking, Spatial Reasoning
## GraphMimic: Graph-to-Graphs Generative Modeling from Videos for Policy Learning
- **Tags:** Graph Neural Networks (GNNs), Embodied AI, Graph-to-Graphs Generative Modeling, Cross-Embodiment Learning, Robotic Skill Acquisition
## MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond
- **Tags:** 3D Human Pose Estimation, Embodied AI, Pressure Sensing, Cross-Modal Fusion, Physical Plausibility
## MobileH2R: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic Data
- **Tags:** Embodied AI, Data Augmentation, 4D Imitation Learning, Base-Arm Coordination, Synthetic Data Generation
## Ges3ViG : Incorporating Pointing Gestures into Language-Based 3D Visual Grounding for Embodied Reference Understanding
- **Tags:** Embodied AI, 3D Point Cloud, Data Augmentation, 3D Visual Grounding, Pointing Gestures, Benchmark Dataset
## PhysVLM: Enabling Visual Language Models to Understand Robotic Physical Reachability
- **Tags:** Vision-Language Models (VLMs), Embodied AI, Robotic Physical Reachability, Space-Physical Reachability Map (S-P Map), Multi-Robot Dataset
- **Link:** [Link](https://github.com/unira-zwj/PhysVLM)

