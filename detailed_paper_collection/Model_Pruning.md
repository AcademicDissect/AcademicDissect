# **Model Pruning - Full Paper Collection**

## Graph-Embedded Structure-Aware Perceptual Hashing for Neural Network Protection and Piracy Detection
- **Tags:** Graph Neural Networks (GNNs), Model Pruning, Perceptual Hashing, Copyright Protection, Neural Network Structures
## CASP: Compression of Large Multimodal Models Based on Attention Sparsity
- **Tags:** Multimodal Large Language Models (MLLMs), Model Pruning, Attention Sparsity, Low-Rank Decomposition, Optimal Bit Allocation
## PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Token Reduction, Clustering Algorithm, FlashAttention Compatibility
## EffiDec3D: An Optimized Decoder for High-Performance and Efficient 3D Medical Image Segmentation
- **Tags:** 3D Semantic Segmentation, Medical Image Segmentation, Model Pruning, Channel Reduction, High-Resolution Layer Removal, Computational Efficiency
## GliaNet: Adaptive Neural Network Structure Learning with Glia-Driven
- **Tags:** Neural Architecture Search (NAS), Model Pruning, Biomimetic Neural Networks, Adaptive Neural Structure Optimization, Glial Cell-Inspired Learning
## Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives
- **Tags:** 3DGS (Gaussian Splatting), 3D Reconstruction, Rendering Optimization, Model Pruning, Real-Time Rendering
## TinyFusion: Diffusion Transformers Learned Shallow
- **Tags:** Diffusion Models, Model Pruning, Differentiable Sampling, Layer Pruning, Recoverability Optimization
## TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Inference Time Optimization, FlashAttention Compatibility, KV Cache Reduction, Visual Token Pruning
## Learning Compatible Multi-Prize Subnetworks for Asymmetric Retrieval
- **Tags:** Knowledge Distillation, Model Pruning, Post-Training Pruning, Conflict-Aware Gradient Integration, Self-Compatible Networks
## Task Singular Vectors: Reducing Task Interference in Model Merging
- **Tags:** Model Pruning, Knowledge Distillation, Singular Value Decomposition, Task Interference Reduction, Layer-Level Analysis
## PUP 3D-GS: Principled Uncertainty Pruning for 3D Gaussian Splatting
- **Tags:** 3DGS (Gaussian Splatting), Model Pruning, Sensitivity Pruning, Multi-round Prune-refine Pipeline, High Compression Ratios
## How to Merge Your Multimodal Models Over Time?
- **Tags:** Multimodal Learning, Model Pruning, Temporal Model Merging, Continual Learning, Multimodal Pretraining
## APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian Based Reconstruction for Vision Transformers
- **Tags:** Vision Transformer (ViT), Model Pruning, Post-Training Quantization, Hessian Loss, Activation Function Optimization
## Enhancing Diversity for Data-free Quantization
- **Tags:** Model Pruning, Data Augmentation, Quantization, Mode Collapse, Feature Diversity
- **Link:** [Link](https://anonymous.4open.science/r/DFQ-84E6)

## DeepCompress-ViT: Rethinking Model Compression to Enhance Efficiency of Vision Transformers at the Edge
- **Tags:** Vision Transformer (ViT), Model Pruning, Unified Compression Training (UCT), Edge Computing, Matrix Multiplication Optimization
## Once-Tuning-Multiple-Variants: Tuning Once and Expanded as Multiple Vision-Language Model Variants
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Dynamic Weight Expansion, Mathematical Series Expansion, Inference Optimization
## MDP: Multidimensional Vision Model Pruning with Latency Constraint
- **Tags:** Model Pruning, Latency Constraint, Mixed-Integer Nonlinear Program, Latency Modeling, Transformer Optimization
## Two is Better than One: Efficient Ensemble Defense for Robust and Compact Models
- **Tags:** Model Pruning, Knowledge Distillation, Adversarial Robustness, Ensemble Learning, Resource Efficiency
## AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization
- **Tags:** Multimodal Large Language Models (MLLMs), Model Pruning, Unsupervised Learning, Linear Interpolation, Hyper-parameter Optimization
## Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning
- **Tags:** Object Detection, Model Pruning, Sensitivity-Guided Pruning, Stochastic Channel Reactivation, Domain Adaptation
## FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation
- **Tags:** Vision Transformer (ViT), Model Pruning, Quantization Loss, Fisher Information Matrix, Low-Bit Quantization
## EdgeTAM: On-Device Track Anything Model
- **Tags:** Video Object Segmentation, Model Pruning, 2D Spatial Perceiver, Memory Attention Optimization, On-Device AI
## Efficient Fine-Tuning and Concept Suppression for Pruned Diffusion Models
- **Tags:** Diffusion Models, Model Pruning, Bilevel Optimization, Concept Unlearning, Knowledge Distillation
## BHViT: Binarized Hybrid Vision Transformer
- **Tags:** Vision Transformer (ViT), Model Pruning, Binarization, Shift Operations, Quantization Decomposition
## EfficientLLaVA:Generalizable Auto-Pruning for Large Vision-language Models
- **Tags:** Multimodal Large Language Models (MLLMs), Model Pruning, Generalization Gap, Structural Risk Minimization, Vision-Language Efficiency
## A Stitch in Time Saves Nine: Small VLM is a Precise Guidance for accelerating Large VLMs
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Attention Mechanisms, Token Pruning, Early Exiting Mechanism
## Flexible Group Count Enables Hassle-Free Structured Pruning
- **Tags:** Model Pruning, Neural Architecture Search (NAS), Grouped Kernel Pruning, Flexible Group Count, Integral Optimization
## WAVE: Weight Templates for Adaptive Initialization of Variable-sized Models
- **Tags:** Knowledge Distillation, Model Pruning, Kronecker Product, Learngene Framework, Variable-sized Models
## Less is More: Efficient Model Merging with Binary Task Switch
- **Tags:** Model Pruning, Knowledge Distillation, Binarized Task Vectors, Automated Switch Combination, Storage Efficiency
## Quantization without Tears
- **Tags:** Model Pruning, Knowledge Distillation, Network Quantization, Lightweight Structures, Closed-Form Solution
## Libra-Merging: Importance-redundancy and Pruning-merging Trade-off for Acceleration Plug-in in Large Vision-Language Model
- **Tags:** Vision-Language Models (VLMs), Model Pruning, Token Compression, Information Compensation, Plug-in Acceleration
## DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models
- **Tags:** Multimodal Large Language Models (MLLMs), Model Pruning, Token Pruning, Diversity Maximization, Inference Efficiency
## Automated Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression
- **Tags:** Model Pruning, Knowledge Distillation, Quantization-aware Training, Structured Pruning, Joint Optimization
## ICP: Immediate Compensation Pruning for Mid-to-high Sparsity
- **Tags:** Model Pruning, Backbone, Sparsity Rearrange, Block-wise Compensate Pruning, Mid-to-high Sparsity
